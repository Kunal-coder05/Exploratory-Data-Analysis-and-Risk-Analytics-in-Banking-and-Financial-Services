# -*- coding: utf-8 -*-
"""EDA Assignment.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1BU0naDmiU0_EZwCYPdzc9ZUsNsfLYhXL
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

import warnings
warnings.filterwarnings('ignore')
pd.set_option("display.max_columns",500)
pd.set_option("display.max_rows",500)

# Read the dataset
app_data = pd.read_csv(r'/content/drive/MyDrive/EDA Assignment/application_data.csv')
app_data.head()

app_data.shape

app_data.info(-1)

### Data Cleaning - Identification of columns with blanks more than 40% 

temp=(100*app_data.isnull().sum()/app_data.shape[0]).reset_index().rename(columns={"index":"column_name",0:"% missing"})
drop_cols=list(temp[temp["% missing"]>=40]["column_name"])

# Eliminating all the columns with more than 40% missing data

app_data=app_data.drop(drop_cols,axis=1)
app_data

app_data.shape  # Post removing the columns with missing data more than 40%, the col no reduced from 112 to 73

app_data.describe()

current_blank=(100*app_data.isnull().sum()/app_data.shape[0])
current_blank.sort_values(ascending=False)

# We are choosing 7 columns for the outliers understanding
app_data.isnull().sum().sort_values(ascending=False)

# Out of 17 outliers we are taking into account only 7 outliers
# Continuous variables -'EXT_SOURCE_2','AMT_GOODS_PRICE'
# Categorical variables - 'OBS_30_CNT_SOCIAL_CIRCLE','OBS_60_CNT_SOCIAL_CIRCLE','DEF_60_CNT_SOCIAL_CIRCLE','DEF_30_CNT_SOCIAL_CIRCLE','NAME_TYPE_SUITE'

# Box plot for EXT_SOURCE_2
plt.figure(figsize=(12,4))
sns.boxplot(app_data['EXT_SOURCE_2'])
plt.show()

# In 'EXT_SOURCE_2' data there are no outliers so the data should be imputed with a median value

plt.figure(figsize=(12,4))
sns.boxplot(app_data['AMT_GOODS_PRICE'])
plt.show()
# In AMT_GOODS_PRICE data there are outliers so the data should be imputed with a median value

nouse=['FLAG_MOBIL', 'FLAG_EMP_PHONE', 'FLAG_WORK_PHONE', 'FLAG_CONT_MOBILE','FLAG_PHONE', 'FLAG_EMAIL',
          'REGION_RATING_CLIENT','REGION_RATING_CLIENT_W_CITY','FLAG_EMAIL','CNT_FAM_MEMBERS', 'REGION_RATING_CLIENT',
          'REGION_RATING_CLIENT_W_CITY','FLAG_DOCUMENT_2', 'FLAG_DOCUMENT_3','FLAG_DOCUMENT_4',
          'FLAG_DOCUMENT_5', 'FLAG_DOCUMENT_6','FLAG_DOCUMENT_7', 'FLAG_DOCUMENT_8', 'FLAG_DOCUMENT_9','FLAG_DOCUMENT_10',
          'FLAG_DOCUMENT_11','FLAG_DOCUMENT_12','FLAG_DOCUMENT_13', 'FLAG_DOCUMENT_14', 'FLAG_DOCUMENT_15',
          'FLAG_DOCUMENT_16', 'FLAG_DOCUMENT_17', 'FLAG_DOCUMENT_18','FLAG_DOCUMENT_19', 'FLAG_DOCUMENT_20',
          'FLAG_DOCUMENT_21','EXT_SOURCE_2','EXT_SOURCE_3']

app_data.drop(labels= nouse,axis=1,inplace=True)

app_data.head()

app_data.shape

print('CODE_GENDER: ',app_data['CODE_GENDER'].unique())
print('No of values: ',app_data[app_data['CODE_GENDER']=='XNA'].shape[0])

XNA_count = app_data[app_data['CODE_GENDER']=='XNA'].shape[0]
per_XNA = round(XNA_count/len(app_data.index)*100,3)

print('% of XNA Values:',  per_XNA)

print('maximum frequency data :', app_data['CODE_GENDER'].describe().top)

app_data = app_data.drop(app_data.loc[app_data['CODE_GENDER']=='XNA'].index)
app_data[app_data['CODE_GENDER']=='XNA'].shape

# Converting '-ve' values into '+ve' Values
app_data['DAYS_BIRTH'] = app_data['DAYS_BIRTH'].abs()
app_data['DAYS_EMPLOYED'] = app_data['DAYS_EMPLOYED'].abs()
app_data['DAYS_REGISTRATION'] = app_data['DAYS_REGISTRATION'].abs()
app_data['DAYS_ID_PUBLISH'] = app_data['DAYS_ID_PUBLISH'].abs()
app_data['DAYS_LAST_PHONE_CHANGE'] = app_data['DAYS_LAST_PHONE_CHANGE'].abs()

app_data.head(5)

# Box plot for selected columns
attr = ['CNT_CHILDREN', 'AMT_INCOME_TOTAL','AMT_CREDIT','AMT_ANNUITY','DAYS_EMPLOYED', 'DAYS_REGISTRATION']

plt.figure(figsize = (20, 15))
for i in enumerate(attr):
  plt.subplot(3, 2, i[0]+1)
  sns.boxplot(x = i[1], data = app_data)
plt.show()

# bins creation
bins = [0,100000,200000,300000,400000,500000,10000000000]
slot = ['<100000', '100000-200000','200000-300000','300000-400000','400000-500000', '500000 and above']

app_data['AMT_INCOME_RANGE']=pd.cut(app_data['AMT_INCOME_TOTAL'],bins,labels=slot)

bins = [0,100000,200000,300000,400000,500000,600000,700000,800000,900000,10000000000]
slot = ['<100000', '100000-200000','200000-300000','300000-400000','400000-500000', '500000-600000',
        '600000-700000','700000-800000','850000-900000','900000 and above']

app_data['AMT_CREDIT_RANGE']=pd.cut(app_data['AMT_CREDIT'],bins,labels=slot)

df_0=app_data[app_data["TARGET"]==0]
df_1=app_data[app_data["TARGET"]==1]

percentage_defaulters= round(100*len(df_1)/(len(df_0)+len(df_1)),2)

percentage_nondefaulters=round(100*len(df_0)/(len(df_0)+len(df_1)),2)

print('Count of df_0:', len(df_0))
print('Count of df_1:', len(df_1))


print('Percentage of people who paid their loan are: ', percentage_nondefaulters, '%' )
print('Percentage of people who did not paid their loan are: ', percentage_defaulters, '%' )

DI = round(len(df_0)/len(df_1),2)

print('Data Imbalance:', DI)

attr = ['AMT_INCOME_RANGE', 'AMT_CREDIT_RANGE','NAME_INCOME_TYPE','NAME_CONTRACT_TYPE']
plt.figure(figsize = (20, 15))

for i in enumerate(attr):
    plt.subplot(2, 2, i[0]+1)
    plt.subplots_adjust(hspace=0.5)
    sns.countplot(x = i[1], hue = 'TARGET', data = app_data)
    
    plt.rcParams['axes.titlesize'] = 16
    
    plt.xticks(rotation = 45)
    plt.yscale('log')

# Categorical Univariate Analysis

attr = ['CODE_GENDER','FLAG_OWN_CAR']
plt.figure(figsize = (20, 10))

for i in enumerate(attr):
    plt.subplot(2, 2, i[0]+1)
    plt.subplots_adjust(hspace=0.5)
    sns.countplot(x = i[1], hue = 'TARGET', data = app_data)
     
    plt.rcParams['axes.titlesize'] = 16
    plt.xticks(rotation = 45)

# Univariate Analysis for continous variable

attr = ['AMT_ANNUITY','AMT_GOODS_PRICE','DAYS_BIRTH','DAYS_EMPLOYED','DAYS_LAST_PHONE_CHANGE','DAYS_ID_PUBLISH']
plt.figure(figsize = (15, 20))

for i in enumerate(attr):
    plt.subplot(3, 2, i[0]+1)
    plt.subplots_adjust(hspace=0.5)
    sns.boxplot(x = 'TARGET', y = i[1], data = app_data)

# Bivariate analysis for numerical variables for Target 0

plt.figure(figsize=(16,12))
plt.xticks(rotation=45)
sns.boxplot(data = df_0, x='NAME_EDUCATION_TYPE',y='AMT_CREDIT', hue ='NAME_FAMILY_STATUS',orient='v')
plt.title('Credit amount vs Education Status')
plt.show()

# Box plotting for credit amount

plt.figure(figsize=(16,12))
plt.xticks(rotation=45)
plt.yscale('log')
sns.boxplot(data = df_0, x='NAME_EDUCATION_TYPE',y='AMT_INCOME_TOTAL', hue ='NAME_FAMILY_STATUS',orient='v')
plt.title('Income amount vs Education Status')
plt.show()

# Box plotting for Income amount

plt.figure(figsize=(15,10))
plt.xticks(rotation=45)
sns.boxplot(data = df_0, x='NAME_EDUCATION_TYPE',y='AMT_CREDIT', hue ='NAME_FAMILY_STATUS',orient='v')
plt.title('Credit Amount vs Education Status')
plt.show()

# Top 10 correlated variables: df_0

corr = df_0.corr()
corrdf = corr.where(np.triu(np.ones(corr.shape), k=1).astype(np.bool))
corrdf = corrdf.unstack().reset_index()
corrdf.columns = ['Var1', 'Var2', 'Correlation']
corrdf.dropna(subset = ['Correlation'], inplace = True)
corrdf['Correlation'] = round(corrdf['Correlation'], 2)
corrdf['Correlation'] = abs(corrdf['Correlation'])
corrdf.sort_values(by = 'Correlation', ascending = False).head(10)

# Top 10 correlated variables: df_1

corr = df_1.corr()
corrdf = corr.where(np.triu(np.ones(corr.shape), k=1).astype(np.bool))
corrdf = corrdf.unstack().reset_index()
corrdf.columns = ['Var1', 'Var2', 'Correlation']
corrdf.dropna(subset = ['Correlation'], inplace = True)
corrdf['Correlation'] = round(corrdf['Correlation'], 2)
corrdf['Correlation'] = abs(corrdf['Correlation'])
corrdf.sort_values(by = 'Correlation', ascending = False).head(10)

# Reading the dataset of previous application

prev_app = pd.read_csv(r'/content/drive/MyDrive/EDA Assignment/previous_application.csv')
prev_app.head()

prev_app.shape

prev_app.info(-1)

temp1=(100*prev_app.isnull().sum()/prev_app.shape[0]).reset_index().rename(columns={"index":"column_name",0:"% missing"})
drop_cols=list(temp1[temp1["% missing"]>=50]["column_name"])

prev_app = prev_app.drop(drop_cols,axis=1)
prev_app

prev_app.shape

# combination of application data and previous app data

comb_data = pd.merge(left=app_data,right=prev_app,how='inner',on='SK_ID_CURR',suffixes='_x')
comb_data.shape

comb_data.head()

comb_data.drop(['SK_ID_CURR','REG_REGION_NOT_LIVE_REGION', 
              'REG_REGION_NOT_WORK_REGION','LIVE_REGION_NOT_WORK_REGION', 'REG_CITY_NOT_LIVE_CITY',
              'REG_CITY_NOT_WORK_CITY', 'LIVE_CITY_NOT_WORK_CITY'],axis=1,inplace=True)

# Performing univariate analysis on combined data


sns.set_style('whitegrid')
sns.set_context('talk')

plt.figure(figsize=(10,15))
plt.rcParams["axes.labelsize"] = 20
plt.rcParams['axes.titlesize'] = 22
plt.rcParams['axes.titlepad'] = 30
plt.xticks(rotation=90)
plt.xscale('log')
plt.title('Distribution of contract status with purposes')
ax = sns.countplot(data = comb_data, y= 'NAME_CASH_LOAN_PURPOSE', 
                   order= comb_data['NAME_CASH_LOAN_PURPOSE'].value_counts().index,hue = 'NAME_CONTRACT_STATUS')

sns.set_style('whitegrid')
sns.set_context('talk')

plt.figure(figsize=(10,20))
plt.rcParams["axes.labelsize"] = 20
plt.rcParams['axes.titlesize'] = 22
plt.rcParams['axes.titlepad'] = 30
plt.xticks(rotation=90)
plt.xscale('log')
plt.title('Distribution of purposes with target ')
ax = sns.countplot(data = comb_data, y= 'NAME_CASH_LOAN_PURPOSE', 
                   order= comb_data['NAME_CASH_LOAN_PURPOSE'].value_counts().index,hue = 'TARGET')